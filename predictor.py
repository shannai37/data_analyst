"""
æ•°æ®åˆ†æå¸ˆæ’ä»¶ - é¢„æµ‹åˆ†ææ¨¡å—

æä¾›åŸºäºå†å²æ•°æ®çš„è¶‹åŠ¿é¢„æµ‹å’Œå¼‚å¸¸æ£€æµ‹åŠŸèƒ½
"""

import numpy as np
import aiosqlite
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

from astrbot.api import logger
from .models import PredictionResult, ActivityAnalysisData
from .database import DatabaseManager


class PredictorService:
    """
    /// é¢„æµ‹åˆ†ææœåŠ¡
    /// åŸºäºå†å²æ•°æ®è¿›è¡Œè¶‹åŠ¿é¢„æµ‹ã€å¼‚å¸¸æ£€æµ‹å’Œæ¨¡å¼è¯†åˆ«
    /// æ”¯æŒå¤šç§é¢„æµ‹ç®—æ³•å’Œç½®ä¿¡åº¦è¯„ä¼°
    """
    
    def __init__(self, db_manager: DatabaseManager):
        """
        /// åˆå§‹åŒ–é¢„æµ‹æœåŠ¡
        /// @param db_manager: æ•°æ®åº“ç®¡ç†å™¨
        """
        self.db_manager = db_manager
        self.min_data_points = 7  # æœ€å°‘éœ€è¦7å¤©æ•°æ®è¿›è¡Œé¢„æµ‹
        self.max_prediction_days = 30  # æœ€å¤§é¢„æµ‹30å¤©
        
        logger.info("é¢„æµ‹åˆ†ææœåŠ¡å·²åˆå§‹åŒ–")
    
    async def predict(self, group_id: str, target: str, days: int) -> Optional[PredictionResult]:
        """
        /// æ‰§è¡Œé¢„æµ‹åˆ†æ
        /// @param group_id: ç¾¤ç»„ID
        /// @param target: é¢„æµ‹ç›®æ ‡ (activity/members/topics)
        /// @param days: é¢„æµ‹å¤©æ•°
        /// @return: é¢„æµ‹ç»“æœ
        """
        try:
            if days <= 0 or days > self.max_prediction_days:
                logger.warning(f"é¢„æµ‹å¤©æ•°è¶…å‡ºèŒƒå›´: {days}")
                return None
            
            if target == "activity":
                return await self._predict_activity(group_id, days)
            elif target == "members":
                return await self._predict_member_growth(group_id, days)
            elif target == "topics":
                return await self._predict_topic_trends(group_id, days)
            else:
                logger.warning(f"ä¸æ”¯æŒçš„é¢„æµ‹ç›®æ ‡: {target}")
                return None
                
        except Exception as e:
            logger.error(f"é¢„æµ‹åˆ†æå¤±è´¥: {e}")
            return None
    
    async def _predict_activity(self, group_id: str, days: int) -> Optional[PredictionResult]:
        """
        /// é¢„æµ‹ç¾¤ç»„æ´»è·ƒåº¦
        /// @param group_id: ç¾¤ç»„ID
        /// @param days: é¢„æµ‹å¤©æ•°
        /// @return: æ´»è·ƒåº¦é¢„æµ‹ç»“æœ
        """
        try:
            # è·å–å†å²æ•°æ®ï¼ˆæœ€è¿‘30å¤©æˆ–æ›´å¤šï¼‰
            historical_period = max(30, days * 2)
            activity_data = await self.db_manager.get_activity_analysis(group_id, f"{historical_period}d")
            
            if not activity_data or not activity_data.daily_data:
                return None
            
            daily_data = activity_data.daily_data
            if len(daily_data) < self.min_data_points:
                return None
            
            # å‡†å¤‡æ•°æ®
            dates = [datetime.strptime(row[0], '%Y-%m-%d') for row in daily_data]
            counts = [row[1] for row in daily_data]
            
            # ä½¿ç”¨å¤šç§é¢„æµ‹æ–¹æ³•
            linear_pred = self._linear_prediction(counts, days)
            trend_pred = self._trend_analysis_prediction(counts, days)
            seasonal_pred = self._seasonal_prediction(counts, days)
            
            # ç»¼åˆé¢„æµ‹ç»“æœ
            predictions = self._combine_predictions([linear_pred, trend_pred, seasonal_pred])
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = self._calculate_confidence(counts, predictions[:len(counts)])
            
            # åˆ†æè¶‹åŠ¿æ–¹å‘
            trend_direction = self._analyze_trend_direction(counts, predictions)
            
            # è®¡ç®—å˜åŒ–ç™¾åˆ†æ¯”
            current_avg = np.mean(counts[-7:]) if len(counts) >= 7 else np.mean(counts)
            future_avg = np.mean(predictions)
            change_percent = ((future_avg - current_avg) / current_avg * 100) if current_avg > 0 else 0
            
            # ç”Ÿæˆæè¿°
            description = self._generate_activity_prediction_description(
                days, future_avg, current_avg, change_percent, confidence, trend_direction
            )
            
            return PredictionResult(
                predictions=predictions,
                confidence=confidence,
                trend_direction=trend_direction,
                change_percent=change_percent,
                description=description
            )
            
        except Exception as e:
            logger.error(f"æ´»è·ƒåº¦é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    async def _predict_member_growth(self, group_id: str, days: int) -> Optional[PredictionResult]:
        """
        /// é¢„æµ‹æˆå‘˜å¢é•¿
        /// @param group_id: ç¾¤ç»„ID
        /// @param days: é¢„æµ‹å¤©æ•°
        /// @return: æˆå‘˜å¢é•¿é¢„æµ‹ç»“æœ
        """
        try:
            # è·å–å†å²ç”¨æˆ·æ´»è·ƒæ•°æ®
            async with aiosqlite.connect(self.db_manager.db_path) as db:
                cursor = await db.execute('''
                    SELECT DATE(timestamp) as date, COUNT(DISTINCT user_id) as active_users
                    FROM messages 
                    WHERE group_id = ? AND timestamp >= ?
                    GROUP BY DATE(timestamp)
                    ORDER BY date
                ''', (group_id, datetime.now() - timedelta(days=30)))
                
                data = await cursor.fetchall()
                
                if len(data) < self.min_data_points:
                    return None
                
                user_counts = [row[1] for row in data]
                
                # ä½¿ç”¨çº¿æ€§å›å½’é¢„æµ‹
                predictions = self._linear_prediction(user_counts, days)
                confidence = self._calculate_confidence(user_counts, predictions[:len(user_counts)])
                
                current_avg = np.mean(user_counts[-7:]) if len(user_counts) >= 7 else np.mean(user_counts)
                future_avg = np.mean(predictions)
                change_percent = ((future_avg - current_avg) / current_avg * 100) if current_avg > 0 else 0
                
                trend_direction = "å¢é•¿" if change_percent > 5 else "ä¸‹é™" if change_percent < -5 else "ç¨³å®š"
                
                description = f"""ğŸ“Š æˆå‘˜æ´»è·ƒåº¦é¢„æµ‹ (æœªæ¥{days}å¤©)

ğŸ” é¢„æµ‹ç»“æœ:
â€¢ é¢„æµ‹å¹³å‡æ´»è·ƒç”¨æˆ·æ•°: {future_avg:.1f}
â€¢ ç›¸æ¯”å½“å‰å˜åŒ–: {change_percent:+.1f}%
â€¢ é¢„æµ‹è¶‹åŠ¿: {trend_direction}
â€¢ ç½®ä¿¡åº¦: {confidence * 100:.1f}%

ğŸ’¡ åˆ†æè¯´æ˜:
åŸºäºæœ€è¿‘{len(user_counts)}å¤©çš„å†å²æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚æˆå‘˜æ´»è·ƒåº¦å—å¤šç§å› ç´ å½±å“ï¼Œ
å®é™…æƒ…å†µå¯èƒ½å› ç¾¤ç»„æ´»åŠ¨ã€è¯é¢˜çƒ­åº¦ç­‰å› ç´ è€Œæœ‰æ‰€ä¸åŒã€‚"""
                
                return PredictionResult(
                    predictions=predictions,
                    confidence=confidence,
                    trend_direction=trend_direction,
                    change_percent=change_percent,
                    description=description
                )
                
        except Exception as e:
            logger.error(f"æˆå‘˜å¢é•¿é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    async def _predict_topic_trends(self, group_id: str, days: int) -> Optional[PredictionResult]:
        """
        /// é¢„æµ‹è¯é¢˜è¶‹åŠ¿
        /// @param group_id: ç¾¤ç»„ID
        /// @param days: é¢„æµ‹å¤©æ•°
        /// @return: è¯é¢˜è¶‹åŠ¿é¢„æµ‹ç»“æœ
        """
        try:
            # è·å–è¯é¢˜æ´»è·ƒåº¦å†å²æ•°æ®
            async with aiosqlite.connect(self.db_manager.db_path) as db:
                cursor = await db.execute('''
                    SELECT DATE(last_mentioned) as date, COUNT(DISTINCT keyword) as topic_count
                    FROM topic_keywords 
                    WHERE group_id = ? AND last_mentioned >= ?
                    GROUP BY DATE(last_mentioned)
                    ORDER BY date
                ''', (group_id, datetime.now() - timedelta(days=30)))
                
                data = await cursor.fetchall()
                
                if len(data) < self.min_data_points:
                    return None
                
                topic_counts = [row[1] for row in data]
                
                # é¢„æµ‹è¯é¢˜å¤šæ ·æ€§
                predictions = self._seasonal_prediction(topic_counts, days)
                confidence = self._calculate_confidence(topic_counts, predictions[:len(topic_counts)])
                
                current_avg = np.mean(topic_counts[-7:]) if len(topic_counts) >= 7 else np.mean(topic_counts)
                future_avg = np.mean(predictions)
                change_percent = ((future_avg - current_avg) / current_avg * 100) if current_avg > 0 else 0
                
                if change_percent > 10:
                    trend_direction = "è¯é¢˜å¤šæ ·åŒ–å¢åŠ "
                elif change_percent < -10:
                    trend_direction = "è¯é¢˜é›†ä¸­åŒ–è¶‹åŠ¿"
                else:
                    trend_direction = "è¯é¢˜ç¨³å®šå‘å±•"
                
                description = f"""ğŸ”¥ è¯é¢˜è¶‹åŠ¿é¢„æµ‹ (æœªæ¥{days}å¤©)

ğŸ“ˆ é¢„æµ‹ç»“æœ:
â€¢ é¢„æµ‹æ—¥å‡æ–°è¯é¢˜æ•°: {future_avg:.1f}
â€¢ è¯é¢˜å¤šæ ·æ€§å˜åŒ–: {change_percent:+.1f}%
â€¢ è¶‹åŠ¿ç‰¹å¾: {trend_direction}
â€¢ ç½®ä¿¡åº¦: {confidence * 100:.1f}%

ğŸ¯ è¶‹åŠ¿åˆ†æ:
{self._generate_topic_trend_insights(change_percent, current_avg, future_avg)}

âš ï¸ æ³¨æ„: è¯é¢˜è¶‹åŠ¿å—ç¾¤ç»„æ´»åŠ¨ã€å¤–éƒ¨äº‹ä»¶ç­‰å¤šç§å› ç´ å½±å“ï¼Œé¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒã€‚"""
                
                return PredictionResult(
                    predictions=predictions,
                    confidence=confidence,
                    trend_direction=trend_direction,
                    change_percent=change_percent,
                    description=description
                )
                
        except Exception as e:
            logger.error(f"è¯é¢˜è¶‹åŠ¿é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def _linear_prediction(self, data: List[float], days: int) -> List[float]:
        """
        /// çº¿æ€§å›å½’é¢„æµ‹
        /// @param data: å†å²æ•°æ®
        /// @param days: é¢„æµ‹å¤©æ•°
        /// @return: é¢„æµ‹ç»“æœ
        """
        if len(data) < 2:
            return [data[0]] * days if data else [0] * days
        
        # å‡†å¤‡æ•°æ®
        X = np.array(range(len(data))).reshape(-1, 1)
        y = np.array(data)
        
        # è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹
        model = LinearRegression()
        model.fit(X, y)
        
        # é¢„æµ‹æœªæ¥æ•°æ®
        future_X = np.array(range(len(data), len(data) + days)).reshape(-1, 1)
        predictions = model.predict(future_X)
        
        # ç¡®ä¿é¢„æµ‹å€¼éè´Ÿ
        predictions = np.maximum(predictions, 0)
        
        return predictions.tolist()
    
    def _trend_analysis_prediction(self, data: List[float], days: int) -> List[float]:
        """
        /// è¶‹åŠ¿åˆ†æé¢„æµ‹
        /// @param data: å†å²æ•°æ®
        /// @param days: é¢„æµ‹å¤©æ•°
        /// @return: é¢„æµ‹ç»“æœ
        """
        if len(data) < 3:
            return self._linear_prediction(data, days)
        
        # è®¡ç®—è¶‹åŠ¿
        recent_window = min(7, len(data) // 2)
        recent_avg = np.mean(data[-recent_window:])
        early_avg = np.mean(data[:recent_window])
        
        trend_slope = (recent_avg - early_avg) / recent_window
        
        # åŸºäºè¶‹åŠ¿é¢„æµ‹
        last_value = data[-1]
        predictions = []
        
        for i in range(1, days + 1):
            predicted_value = last_value + trend_slope * i
            # æ·»åŠ ä¸€äº›éšæœºæ³¢åŠ¨
            noise = np.random.normal(0, np.std(data) * 0.1)
            predictions.append(max(0, predicted_value + noise))
        
        return predictions
    
    def _seasonal_prediction(self, data: List[float], days: int) -> List[float]:
        """
        /// å­£èŠ‚æ€§é¢„æµ‹
        /// @param data: å†å²æ•°æ®
        /// @param days: é¢„æµ‹å¤©æ•°
        /// @return: é¢„æµ‹ç»“æœ
        """
        if len(data) < 7:
            return self._linear_prediction(data, days)
        
        # ç®€å•çš„å‘¨æœŸæ€§æ¨¡å¼æ£€æµ‹
        week_pattern = []
        if len(data) >= 7:
            for i in range(7):
                week_values = [data[j] for j in range(i, len(data), 7)]
                week_pattern.append(np.mean(week_values))
        
        # åŸºäºå‘¨æœŸæ€§æ¨¡å¼é¢„æµ‹
        predictions = []
        for i in range(days):
            pattern_index = i % len(week_pattern)
            base_value = week_pattern[pattern_index]
            
            # æ·»åŠ è¶‹åŠ¿è°ƒæ•´
            trend_factor = 1 + (np.mean(data[-7:]) - np.mean(data[:7])) / np.mean(data[:7])
            predicted_value = base_value * trend_factor
            
            predictions.append(max(0, predicted_value))
        
        return predictions
    
    def _combine_predictions(self, prediction_lists: List[List[float]]) -> List[float]:
        """
        /// ç»„åˆå¤šä¸ªé¢„æµ‹ç»“æœ
        /// @param prediction_lists: å¤šä¸ªé¢„æµ‹ç»“æœåˆ—è¡¨
        /// @return: ç»„åˆåçš„é¢„æµ‹ç»“æœ
        """
        if not prediction_lists:
            return []
        
        # è¿‡æ»¤ç©ºåˆ—è¡¨
        valid_predictions = [p for p in prediction_lists if p]
        if not valid_predictions:
            return []
        
        # è®¡ç®—åŠ æƒå¹³å‡
        weights = [0.4, 0.3, 0.3]  # çº¿æ€§ã€è¶‹åŠ¿ã€å­£èŠ‚æ€§çš„æƒé‡
        combined = []
        
        for i in range(len(valid_predictions[0])):
            weighted_sum = 0
            total_weight = 0
            
            for j, pred_list in enumerate(valid_predictions):
                if i < len(pred_list):
                    weight = weights[j] if j < len(weights) else 1.0 / len(valid_predictions)
                    weighted_sum += pred_list[i] * weight
                    total_weight += weight
            
            combined.append(weighted_sum / total_weight if total_weight > 0 else 0)
        
        return combined
    
    def _calculate_confidence(self, historical: List[float], fitted: List[float]) -> float:
        """
        /// è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦
        /// @param historical: å†å²çœŸå®å€¼
        /// @param fitted: æ¨¡å‹æ‹Ÿåˆå€¼
        /// @return: ç½®ä¿¡åº¦ (0-1)
        """
        try:
            if len(historical) != len(fitted) or len(historical) < 2:
                return 0.5  # é»˜è®¤ä¸­ç­‰ç½®ä¿¡åº¦
            
            # è®¡ç®—RÂ²å†³å®šç³»æ•°
            r2 = r2_score(historical, fitted)
            
            # è®¡ç®—ç›¸å¯¹è¯¯å·®
            mape = np.mean(np.abs((np.array(historical) - np.array(fitted)) / np.maximum(np.array(historical), 1)))
            
            # ç»¼åˆç½®ä¿¡åº¦è¯„ä¼°
            confidence = max(0, min(1, (r2 + (1 - mape)) / 2))
            
            return confidence
            
        except Exception:
            return 0.5
    
    def _analyze_trend_direction(self, historical: List[float], predictions: List[float]) -> str:
        """
        /// åˆ†æè¶‹åŠ¿æ–¹å‘
        /// @param historical: å†å²æ•°æ®
        /// @param predictions: é¢„æµ‹æ•°æ®
        /// @return: è¶‹åŠ¿æè¿°
        """
        if not historical or not predictions:
            return "æœªçŸ¥"
        
        recent_avg = np.mean(historical[-7:]) if len(historical) >= 7 else np.mean(historical)
        predicted_avg = np.mean(predictions)
        
        change_rate = (predicted_avg - recent_avg) / recent_avg if recent_avg > 0 else 0
        
        if change_rate > 0.1:
            return "ä¸Šå‡"
        elif change_rate < -0.1:
            return "ä¸‹é™"
        else:
            return "ç¨³å®š"
    
    def _generate_activity_prediction_description(self, days: int, future_avg: float, 
                                                current_avg: float, change_percent: float, 
                                                confidence: float, trend_direction: str) -> str:
        """ç”Ÿæˆæ´»è·ƒåº¦é¢„æµ‹æè¿°"""
        # è¶‹åŠ¿è¯„ä»·
        if trend_direction == "ä¸Šå‡":
            trend_emoji = "ğŸ“ˆ"
            trend_desc = "ç¾¤ç»„æ´»è·ƒåº¦å°†ä¿æŒä¸Šå‡è¶‹åŠ¿"
        elif trend_direction == "ä¸‹é™":
            trend_emoji = "ğŸ“‰"
            trend_desc = "ç¾¤ç»„æ´»è·ƒåº¦å¯èƒ½æœ‰æ‰€ä¸‹é™"
        else:
            trend_emoji = "ğŸ“Š"
            trend_desc = "ç¾¤ç»„æ´»è·ƒåº¦å°†ä¿æŒç›¸å¯¹ç¨³å®š"
        
        # ç½®ä¿¡åº¦è¯„ä»·
        if confidence > 0.8:
            confidence_desc = "é¢„æµ‹å¯ä¿¡åº¦è¾ƒé«˜"
        elif confidence > 0.6:
            confidence_desc = "é¢„æµ‹æœ‰ä¸€å®šå‚è€ƒä»·å€¼"
        else:
            confidence_desc = "é¢„æµ‹ä»…ä¾›å‚è€ƒï¼Œå®é™…æƒ…å†µå¯èƒ½æœ‰è¾ƒå¤§å˜åŒ–"
        
        # å˜åŒ–å¹…åº¦è¯„ä»·
        if abs(change_percent) > 20:
            change_desc = "å˜åŒ–å¹…åº¦è¾ƒå¤§"
        elif abs(change_percent) > 10:
            change_desc = "æœ‰æ˜æ˜¾å˜åŒ–è¶‹åŠ¿"
        else:
            change_desc = "å˜åŒ–å¹…åº¦è¾ƒå°"
        
        return f"""{trend_emoji} æ´»è·ƒåº¦é¢„æµ‹ (æœªæ¥{days}å¤©)

ğŸ“Š é¢„æµ‹ç»“æœ:
â€¢ é¢„æµ‹å¹³å‡æ—¥æ¶ˆæ¯æ•°: {future_avg:.1f}
â€¢ ç›¸æ¯”å½“å‰å˜åŒ–: {change_percent:+.1f}%
â€¢ ç½®ä¿¡åº¦: {confidence * 100:.1f}%

ğŸ“ˆ è¶‹åŠ¿åˆ†æ:
{trend_desc}ï¼Œ{change_desc}ã€‚

ğŸ¯ é¢„æµ‹è¯„ä¼°:
{confidence_desc}ã€‚å»ºè®®ç»“åˆå®é™…ç¾¤ç»„æ´»åŠ¨å’Œå¤–éƒ¨å› ç´ ç»¼åˆåˆ¤æ–­ã€‚

âš ï¸ æ³¨æ„: é¢„æµ‹ç»“æœåŸºäºå†å²æ•°æ®æ¨¡å¼ï¼Œå®é™…æƒ…å†µå¯èƒ½å—ç¾¤ç»„äº‹ä»¶ã€èŠ‚å‡æ—¥ã€è¯é¢˜çƒ­åº¦ç­‰å¤šç§å› ç´ å½±å“ã€‚"""
    
    def _generate_topic_trend_insights(self, change_percent: float, current_avg: float, future_avg: float) -> str:
        """ç”Ÿæˆè¯é¢˜è¶‹åŠ¿æ´å¯Ÿ"""
        if change_percent > 15:
            return "é¢„è®¡ç¾¤ç»„è¯é¢˜å°†æ›´åŠ å¤šæ ·åŒ–ï¼Œå¯èƒ½å‡ºç°æ›´å¤šæ–°çš„è®¨è®ºæ–¹å‘ã€‚å»ºè®®å…³æ³¨æ–°å…´è¯é¢˜ï¼Œé€‚æ—¶å¼•å¯¼è®¨è®ºã€‚"
        elif change_percent < -15:
            return "é¢„è®¡ç¾¤ç»„è¯é¢˜å°†è¶‹äºé›†ä¸­åŒ–ï¼Œè®¨è®ºå¯èƒ½å›´ç»•å°‘æ•°çƒ­é—¨è¯é¢˜ã€‚å»ºè®®ä¸»åŠ¨å¼•å…¥æ–°è¯é¢˜ï¼Œä¿æŒè®¨è®ºæ´»åŠ›ã€‚"
        else:
            return "é¢„è®¡ç¾¤ç»„è¯é¢˜å°†ä¿æŒå½“å‰çš„å¤šæ ·æ€§æ°´å¹³ï¼Œè®¨è®ºå†…å®¹ç›¸å¯¹ç¨³å®šã€‚"
    
    async def detect_anomalies(self, group_id: str, days: int = 30) -> Optional[Dict[str, Any]]:
        """
        /// å¼‚å¸¸æ£€æµ‹
        /// @param group_id: ç¾¤ç»„ID
        /// @param days: æ£€æµ‹æ—¶é—´èŒƒå›´
        /// @return: å¼‚å¸¸æ£€æµ‹ç»“æœ
        """
        try:
            activity_data = await self.db_manager.get_activity_analysis(group_id, f"{days}d")
            if not activity_data or not activity_data.daily_data:
                return None
            
            counts = [row[1] for row in activity_data.daily_data]
            
            # ä½¿ç”¨ç»Ÿè®¡æ–¹æ³•æ£€æµ‹å¼‚å¸¸
            mean_val = np.mean(counts)
            std_val = np.std(counts)
            threshold = 2 * std_val  # 2å€æ ‡å‡†å·®
            
            anomalies = []
            for i, count in enumerate(counts):
                if abs(count - mean_val) > threshold:
                    anomalies.append({
                        'date': activity_data.daily_data[i][0],
                        'value': count,
                        'deviation': abs(count - mean_val),
                        'type': 'high' if count > mean_val else 'low'
                    })
            
            return {
                'total_anomalies': len(anomalies),
                'anomalies': anomalies,
                'mean_value': mean_val,
                'std_value': std_val,
                'detection_threshold': threshold
            }
            
        except Exception as e:
            logger.error(f"å¼‚å¸¸æ£€æµ‹å¤±è´¥: {e}")
            return None
